# 神经网络与文本处理（DL与NLP）
## 前几节课的复习
![image.png](attachment:8b14dc79-f9f7-4162-a554-8669d56601f7.png)

## 神经网络的基本概念

### 发展历程（简单介绍）

### 神经网络的基本架构（层次结构）
输入层、输出层、隐藏层。
只能前层向后层传播
同层不能进行信息交换
![image.png](attachment:87d9b6c6-c241-431b-bfd0-00bc87ad2560.png)

### 生物神经元与人工神经元类比
激活函数的概念

#### 简单介绍为什么 DL 比 ML 更高级，更复杂
DL是多模型组成的网络
1. 一个神经网络即是一个综合体模型
2. DL 是矩阵运算、ML是单纯的加减乘除
3. 运算机制和数据规模
![image.png](attachment:11ebe345-515e-4b44-87f0-306d44d5c7fb.png)

### 简单介绍神经网络工作原理

## 神经网络的发展历程
### 第一次浪潮：感知器时代（简单介绍）
#### 简单介绍 XOR 问题 
### 第二次浪潮：反向传播复兴
### 第三次浪潮：深度学习革命
#### 生成对抗网络的简单介绍 
![image.png](attachment:5251a03c-0a1b-4dfe-80ec-a6cdcb8ea740.png)

## 神经网络的拓扑结构
### 网络结构类型
#### 时序数据与时序问题的简单介绍
![image.png](attachment:f2b9f585-6388-43f5-8e85-9e25a1cc9358.png)

## 感知器和激活函数（重点）
### 激活函数详解（重点）
激活函数是NN中的非线性变化器
线性model非常局限：1.无法学习复杂的情况。2. 表达能力有限

### 什么样的函数可以作为激活函数
不是什么函数都适合做激活函数的
#### 梯度消失问题
#### 梯度爆炸问题

###  常见的激活函数，以及适用场景
![image.png](attachment:cb031cf1-36a4-4f8e-bcb8-ae5642756a79.png)
#### sigmoid 函数
定义域值域、优缺点、处理方式、适用场景

#### Tanh 函数
定义域值域、优缺点、处理方式、适用场景
缺陷。值域能等于0
LSTM、GRU、RNN
#### ReLU 函数
定义域值域、优缺点、处理方式、适用场景
CNN、大模型
#### Softmax 函数
定义域值域、优缺点、处理方式、适用场景
隐藏层


## 数据的传播
### 前向传播
### 反向传播

## 文本预处理流程
### 文本清洗
### 中文分词
如何让 model 学会分词
### 停用词过滤
### 其他处理
![image.png](attachment:db4b204a-86e4-46d5-9bd1-a3e8a1840d7f.png)

## 梯度下降算法（重点！！）
### 数学中的最小值探索
导数 -> 极值 -> 最值
### 如何找到工程中的 loss 最小值
两个关键点
1. 导数 ---> 梯度
2. η ----> 步长（人为参数）（可通过优化器找到）

### BGD 算法
![image.png](attachment:af104a2a-8acc-47df-85e1-9188cb9aa967.png)
优点：
缺点：慢，计算复杂

### SGD 算法
优点：快
缺点：不稳定

### MBGD 算法
![image.png](attachment:7f957ba2-723c-47eb-a815-8ec2b94f8270.png)
BGD和SGD的中和
优点：
缺点：

### 凸函数、凸优化等问题
![image.png](attachment:3e4f4de8-9c16-4109-8417-c71e043e16a5.png)


## CNN 算法
### CNN 特征介绍与结构
### 卷积层原理
#### 卷积的计算（补充）
### 池化层的效果